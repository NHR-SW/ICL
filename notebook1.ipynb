{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TUF9t8DkBki"
      },
      "source": [
        "# **Basic in-context learning demonstration**\n",
        "\n",
        "In this first notebook, we will show a very simple introduction to in-context learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhkMOok0kIRe"
      },
      "source": [
        "## Setup\n",
        "\n",
        "First, let's install and import the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_isxsfR9gcpO"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "!pip freeze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_-RDlLPgmhp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "client = AzureOpenAI(\n",
        "  api_key = \"13d8d0888405404b9c1ee4407ad19226\",\n",
        "  api_version = \"2023-07-01-preview\",\n",
        "  azure_endpoint =  \"https://openai-resource-for-multilingual.openai.azure.com/\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiOJPM2skO3Z"
      },
      "source": [
        "During this hands-on session, we will use `gpt-3.5-turbo` and we will also use this helper function to easily test different in-context learning (ICL) approaches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "JeIS34Whgsia"
      },
      "outputs": [],
      "source": [
        "def get_completion(prompt, model=\"gpt-35-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    #return response.choices[0].message[\"content\"]\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt1824V4kUiG"
      },
      "source": [
        "## First steps\n",
        "\n",
        "As we have seen, LLM demonstrates an in-context learning (ICL) ability. In other words, they can learn from a few examples in the context. These examples are usually written in natural language templates. In this section, we will work with a couple of examples using sentiment analysis as our task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7f4E3fggwmB"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "Review: A wonderful little production. Sentiment: Positive \\\n",
        "Review: Wow, what a bad film. Sentiment:\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FldPrVykbGb"
      },
      "source": [
        "We could consider, for example, adding more demonstrations to our prompt.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuAucaYxjyDm"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "Review: A wonderful little production. Sentiment: Positive \\\n",
        "Review: Bad plot, bad dialogue, bad acting. Sentiment: Negative \\\n",
        "Review: Such a boring movie. Sentiment: Negative \\\n",
        "Review:  A realistic portrayal of daily urban routines. Sentiment: Neutral \\\n",
        "Review: Wow, what a bad film. Sentiment:\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCD5VTp3kc11"
      },
      "source": [
        "These were very basic templates, but there are several things we can play with in these prompts. For example, the formatting, the amount of demonstrations, the quality, the ordering, etc. For example, the same example we just tested can be reformated to:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCLuM3S2j2dC"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "You are an NLP assistant for sentiment analysis in English. Give your answer as \"positive\", \"negative\" or \"neutral\". \\\n",
        "Demonstration(s): A wonderful little production. What is the sentiment of this statement? Answer: Positive \\\n",
        "Test Input: Wow, what a bad film. What is the sentiment of this statement? Answer:\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
