{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **The Impact of Demonstration Quality**\n",
        "\n",
        "For this second exercise we will test how different qualities of demonstrations can affect our results using machine translation as our task."
      ],
      "metadata": {
        "id": "6I7kBWLtFef6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "Once again, let's start by installing and import the necessary libraries."
      ],
      "metadata": {
        "id": "h1RmWXcCGMGk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGQeC7--Ep3E"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "!pip freeze"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "client = AzureOpenAI(\n",
        "  api_key = \"13d8d0888405404b9c1ee4407ad19226\",\n",
        "  api_version = \"2023-07-01-preview\",\n",
        "  azure_endpoint =  \"https://openai-resource-for-multilingual.openai.azure.com/\"\n",
        ")"
      ],
      "metadata": {
        "id": "QkOYQnVIFBkW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once again we will use the `get_completion` function to make the runs more convinient."
      ],
      "metadata": {
        "id": "o-L5RmHfHEbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt, model=\"gpt-35-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "B7XucNUYGsaF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demonstration Quality\n",
        "\n",
        "As we said in the last notebook, there are a series of attributes of the prompt we can play around with to try to improve the performance of the model in our particular task. In this notebook, we will focus on the quality of the demonstration using Machine Translation as our task. As you might know, LLMs are already able to perform fairly well in this task, so these examples are merely illustrative. For our particular case, we will use English-to-Spanish translation, **feel free to use any other pair of languages you know** to evaluate these techniques."
      ],
      "metadata": {
        "id": "GZhIxnCqHISM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First example\n",
        "\n",
        "We will start with low-quality demonstrations, which we will slowly improve. To achieve this, we will start with a random pairing of sentences as source and target in our demonstrations."
      ],
      "metadata": {
        "id": "5tnzxm07HK7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following English text to Spanish:\n",
        "Source: Spain is the host country for the Olympics in 1992. Target: Me caso la próxima semana.\n",
        "Source: It's not as easy as people think. Target: Los zapatos de Tom le están demasiado grandes.\n",
        "Source: Please don't walk so fast. Target: ¿Qué tren vas a coger?\n",
        "Source: The smallest field has only two elements: 0 and 1. Target:\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "zIf29UyQHJ03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Second example\n",
        "\n",
        "In this second example, we will pass the correct translations by tweaking the sentences a bit, for example, by eliminating some words from the demonstrations (either from the source or from the target sentence)."
      ],
      "metadata": {
        "id": "QQSHQkHaHOn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following English text to Spanish:\n",
        "Source: Spain is the host country for the Olympics in 1992. Target: España la sede de las Olimpiadas de 1992.\n",
        "Source: It's not as easy as people think. Target: Es tan fácil como la gente piensa.\n",
        "Source: Don't walk so fast. Target: Por favor, no camines tan rápido.\n",
        "Source: The smallest field has only two elements: 0 and 1. Target:\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "1OBkcl7YHA9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Third Example\n",
        "\n",
        "For the next step, we will pass the correct translations for the same sentences we used in the last two examples."
      ],
      "metadata": {
        "id": "RdWnnaysHURQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following English text to Spanish:\n",
        "Source: Spain is the host country for the Olympics in 1992. Target: España fue la sede de las Olimpiadas de 1992.\n",
        "Source: It's not as easy as people think. Target: No es tan fácil como la gente piensa.\n",
        "Source: Please don't walk so fast. Target: Por favor, no camines tan rápido.\n",
        "Source: The smallest field has only two elements: 0 and 1. Target:\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "thKfm2hiHWq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Forth example\n",
        "\n",
        "Lastly, for our last example, we selected a series of sentences from the same domain as our target sentence to see if this influences the performance."
      ],
      "metadata": {
        "id": "uqU3lu2cHanV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following English text to Spanish:\n",
        "Source: Associativity of addition and multiplication. Target: Asociatividad de la adición y la multiplicación.\n",
        "Source: A field is a fundamental algebraic structure. Target: Un cuerpo es una estructura algebraica fundamental.\n",
        "Source: Rational numbers are numbers that can be written as fractions. Target: Los números racionales son números que pueden ser escritos como fracciones.\n",
        "Source: The smallest field has only two elements: 0 and 1. Target:\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "0TJEs9CyHbuh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}